#! /usr/bin/python3

"""Render a set of mdoc(7)-format man pages as HTML, using mandoc(1) for
the bulk of the work, but making the following set of improvements
to that utility's HTML output:

 * Minimize all whitespace (except within <pre>).
 * Remove comments, except for the first one, which is reformatted and
   moved after <html><head><meta charset="utf-8">.
 * Convert HTML entities to UTF-8 text to the extent possible
   (&lt; &gt; &amp; remain).
 * Eliminate XMLisms like <meta/>.
 * Remove bogus title="Xx" attributes from many tags.
 * Add a language attribute to the <html> element.
 * Compensate for mandoc not currently supporting macros inside
   tbl(1) tables (this is specific to the way tbl(1) tables are used
   in ATTRIBUTES sections).
 * Replace the stock inline <style> with a link to an out-of-line css file
   (name specifiable on the command line).
 * Convert non-semantic constructs like <table class="head"> to
   semantic equivalents like <header>, and kludges like
   <div>&#x00A0;</div> to presentational elements like <br>.
 * Make the section and paragraph structure explicit for ease of styling.
 * Add a <nav> list allowing one to jump to any section.

"""

import argparse
import collections
from   contextlib   import contextmanager
import datetime
from   functools    import partial
import os
from   random       import Random
import re
import subprocess
import sys
from   tempfile     import mkstemp
from   urllib.parse import urljoin

import html5lib

#
# Utility routines for HTML processing
#

def fix_class_attr(attrs):
    # You can't write class="whatever" in a function call expression
    # in Python, because "class" is a keyword.
    if 'class' not in attrs:
        for class_alt in 'cls', 'class_', 'klass', 'className':
            if class_alt in attrs:
                attrs['class'] = attrs[class_alt]
                del attrs[class_alt]
                break

def empty_tag(tag, **attrs):
    fix_class_attr(attrs)
    return { "type": "EmptyTag", "name": tag, "data": attrs }

def start_tag(tag, **attrs):
    fix_class_attr(attrs)
    return { "type": "StartTag", "name": tag, "data": attrs }

def end_tag(tag):
    return { "type": "EndTag", "name": tag }

def text_node(text):
    return { "type": "Characters", "data": text }

#
# Individual transformations
#

UNWANTED_ATTRS = frozenset((
    "style", "onabort", "onauxclick", "onblur", "oncancel",
    "oncanplay", "oncanplaythrough", "onchange", "onclick", "onclose",
    "oncontextmenu", "oncuechange", "ondblclick", "ondrag",
    "ondragend", "ondragenter", "ondragexit", "ondragleave",
    "ondragover", "ondragstart", "ondrop", "ondurationchange",
    "onemptied", "onended", "onerror", "onfocus", "oninput",
    "oninvalid", "onkeydown", "onkeypress", "onkeyup", "onload",
    "onloadeddata", "onloadedmetadata", "onloadend", "onloadstart",
    "onmousedown", "onmouseenter", "onmouseleave", "onmousemove",
    "onmouseout", "onmouseover", "onmouseup", "onwheel", "onpause",
    "onplay", "onplaying", "onprogress", "onratechange", "onreset",
    "onresize", "onscroll", "onsecuritypolicyviolation", "onseeked",
    "onseeking", "onselect", "onstalled", "onsubmit", "onsuspend",
    "ontimeupdate", "ontoggle", "onvolumechange", "onwaiting",
))

def remove_unwanted(events):
    """Preliminary cleanup on the raw stream of events generated by the
       DOM walker:

         * For ease of subsequent processing, strip insignificant
           namespace annotations from all attributes.  A namespace is
           insignificant if it is either None or the XHTML namespace.

         * mandoc(1) generates title attributes on many elements that
           duplicate the class attribute for that element, which is
           usually a cryptic code (the name of the roff macro that
           produced the element) and never actually desirable to
           display.  Remove these titles.  Also remove inline styles
           and event attributes.

         * Discard all "script" and "style" elements and their
           contents.  Also discard all comments but the first, which
           is the copyright boilerplate, and any <meta http-equiv="">
           or <meta charset=""> tags.
    """
    saw_first_comment = False
    in_discard = 0
    tag_stack = []
    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            tag_stack.append(ev["name"])
            if ev["name"] in ("script", "style"):
                in_discard += 1
            else:
                attrs = {}
                for attr, val in ev["data"].items():
                    if (isinstance(attr, tuple) and len(attr) == 2 and
                        attr[0] in (None, "http://www.w3.org/1999/xhtml")):
                        attr = attr[1]
                    if attr not in UNWANTED_ATTRS:
                        attrs[attr] = val
                if ("title" in attrs and "class" in attrs and
                    attrs["title"] == attrs["class"]):
                    del attrs["title"]
                ev["data"] = attrs
                yield ev

        elif ty == "EndTag":
            closing = tag_stack.pop()
            assert closing == ev["name"]
            if not in_discard:
                yield ev
            if closing in ("script", "style"):
                in_discard -= 1

        elif ty == "EmptyTag":
            if (in_discard or
                (ev["name"] == "meta" and
                 ("charset" in ev["data"] or
                  "http-equiv" in ev["data"]))):
                continue
            yield ev

        elif ty == "Comment":
            if not in_discard:
                if not saw_first_comment:
                    yield ev
                    saw_first_comment = True

        else:
            if not in_discard:
                yield ev

    assert not tag_stack

def fixup_mandoc_pseudos(events):
    """Make the HTML more semantic in ways that can be done by looking
       only at single elements or short sequences of elements and text:

        <div class="Pp"></div>              <p>
        <div>&nbsp;</div>                   <br>
        <div class="manual-text">...</div>  <main>...</main>
        <div class="Nd">...</div>           <span class="Nd">...</span>
        <div class="Bd ...">...</div>       <figure class="...">...</figure>
        <span [class="No"]>...</span>       ...
    """
    tag_stack = []
    pending = []
    replace_state = None
    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            if pending:
                # The divs that we completely replace with something else
                # never contain nested elements.
                yield from pending
                del pending[:]
                replace_state = None

            nm = ev["name"]
            tag_stack.append(nm)

            if nm == "div":
                attrs = ev["data"]
                if not attrs:
                    pending.append(ev)
                    replace_state = "maybe_br"
                    continue
                if len(attrs) == 1 and "class" in attrs:
                    cls = set(attrs["class"].split())
                    if "Pp" in cls:
                        pending.append(ev)
                        replace_state = "maybe_Pp"
                        continue
                    elif "manual-text" in cls:
                        tag_stack[-1] = "main"
                        yield start_tag("main")
                        continue
                    elif "Nd" in cls:
                        tag_stack[-1] = "span"
                        yield start_tag("span", cls=" ".join(sorted(cls)))
                        continue
                    elif "Bd" in cls:
                        cls.discard("Bd")
                        tag_stack[-1] = "figure"
                        yield start_tag("figure", cls=" ".join(sorted(cls)))
                        continue

            elif nm == "span":
                attrs = ev["data"]
                if (not attrs or
                    (len(attrs) == 1 and "class" in attrs and
                     attrs["class"] == "No")):
                    tag_stack[-1] = "span-No"
                    continue

            yield ev

        elif ty == "EndTag":
            nm = ev["name"]
            closing = tag_stack.pop()
            if nm == "div":
                if closing in ("main", "span", "figure"):
                    assert not pending
                    assert replace_state is None
                    yield end_tag(closing)
                else:
                    assert closing == "div"
                    if replace_state == "maybe_br":
                        yield empty_tag("br")
                    elif replace_state == "maybe_Pp":
                        yield empty_tag("p")
                    else:
                        yield from pending
                        yield ev
                    replace_state = None
                    del pending[:]

            elif nm == "span":
                assert not pending
                assert replace_state is None
                if closing != "span-No":
                    assert closing == "span"
                    yield ev

            else:
                assert closing == nm
                assert not pending
                assert replace_state is None
                yield ev

        elif ty in ("Characters", "SpaceCharacters"):
            if replace_state == "maybe_br" and ev["data"] == "\u00A0":
                pending.append(ev)
            else:
                if pending:
                    yield from pending
                    del pending[:]
                    replace_state = None
                yield ev

        else:
            if pending:
                yield from pending
                del pending[:]
                replace_state = None
            yield ev

    assert not tag_stack
    assert not pending
    assert replace_state is None

def unlink_literals(events):
    """Correct for a mandoc bug: anything inside .Bl -tag that's
       rendered with <code> will also be made into an addressable
       fragment. This is indeed desirable for stuff on an .It line
       (e.g. specific errno codes), but not for stuff that goes into
       the body of each tagged list item.  For instance:

          .Bl -tag
          .It zork
          .Li greeble

       generates

          <dl>
          <dt>zork</dt>
          <dd>
            <a class="permalink" href="#greeble">
              <code id="greeble" class="Li">greeble</code>
            </a>
          </dd>

       Turn this into

          <dl>
          <dt>zork</dt>
          <dd><code class="Li">greeble</code></dd>
    """

    def unlink_literal(evlist):
        assert len(evlist) >= 2
        assert evlist[0]["type"] == "StartTag"
        assert evlist[0]["name"] == "a"
        assert evlist[0]["data"]["class"] == "permalink"
        assert evlist[-1]["type"] == "EndTag"
        assert evlist[-1]["name"] == "a"

        if len(evlist) <= 4:
            return evlist
        if (evlist[1]["type"] != "StartTag"
            or evlist[1]["name"] != "code"):
            return evlist

        assert evlist[-2]["type"] == "EndTag"
        assert evlist[-2]["name"] == "code"

        evlist = evlist[1:-1]
        del evlist[0]["data"]["id"]
        return evlist

    tag_stack = []
    sect_link = []
    in_dd = 0
    in_sect_link = 0
    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            nm = ev["name"]
            tag_stack.append(nm)
            if nm == "dd":
                in_dd += 1
            if nm == "a" and ev["data"]["class"] == "permalink":
                 in_sect_link += 1

        if in_sect_link and in_dd:
             sect_link.append(ev)
        else:
            yield ev

        if ty == "EndTag":
            closing = tag_stack.pop()
            assert closing == ev["name"]
            if closing == "a" and in_sect_link:
                if sect_link:
                    yield from unlink_literal(sect_link)
                    del sect_link[:]
                in_sect_link -= 1
            if closing == "dd":
                in_dd -= 1

# This is not quite the complete list of HTML5 "phrasing content"
# elements: some elements that would be troublesome, and that we know
# will never occur, have been omitted (such as form controls and other
# interactive greeblies).
PHRASING_CONTENT = frozenset((
    "a", "abbr", "b", "bdi", "bdo", "br", "cite", "code", "data", "del",
    "dfn", "em", "i", "img", "ins", "kbd", "mark", "math", "q", "ruby",
    "rp", "rt", "s", "samp", "small", "span", "strong", "sub", "sup",
    "time", "u", "var", "wbr",
))
def form_paragraphs(events):
    """Using an approximation to the HTML5 definition of a paragraph
       (ignoring the possibility of a/ins/del/map elements spanning
       more than one paragraph), inject explicit <p> tags surrounding
       each paragraph.
    """
    in_body = 0
    tag_stack = []
    run = []

    def emit_run(parent):
        nonlocal tag_stack, run, in_body
        assert in_body
        if not run: return
        if parent in ("pre", "h1", "h2", "h3", "h4", "h5", "h6",
                      "table", "tr", "td", "dt"):
            yield from run
        else:
            yield start_tag("p")
            yield from run
            yield end_tag("p")
        del run[:]

    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            prev = tag_stack[-1] if tag_stack else None
            tag = ev["name"]
            tag_stack.append(tag)

            if tag == "body":
                assert not run
                assert in_body == 0
                in_body += 1
                yield ev
                continue

            # Pass through everything until we get to the <body>.
            if not in_body:
                yield ev
                continue

            if tag in PHRASING_CONTENT:
                run.append(ev)
            else:
                assert prev is not None
                yield from emit_run(prev)
                yield ev

        elif ty == "EndTag":
            tag = ev["name"]
            closing = tag_stack.pop()
            assert tag == closing
            if not in_body:
                assert not run
                yield ev
                continue

            if tag in PHRASING_CONTENT:
                run.append(ev)
            else:
                yield from emit_run(tag)
                yield ev
                if tag == "body":
                    in_body -= 1
                    assert in_body == 0

        elif ty == "EmptyTag":
            if not in_body:
                assert not run
                yield ev
                continue

            tag = ev["name"]
            if tag in PHRASING_CONTENT:
                run.append(ev)
            else:
                yield from emit_run(tag_stack[-1])
                # swallow empty "p" tags, they've done their job by
                # flushing the previous run if any
                if tag != "p":
                    yield ev

        elif ty in ("Characters", "SpaceCharacters"):
            if not in_body:
                assert not run
                yield ev
                continue

            # text nodes are phrasing content
            run.append(ev)
            continue

        else:
            if not in_body:
                assert not run
                yield ev
                continue

            yield from emit_run(tag_stack[-1])
            yield ev

    assert not tag_stack
    assert not run
    assert not in_body

# Outside <pre>, all runs of most Unicode whitespace should be reduced
# to a single space.  split() is too aggressive: it discards all of
# the following characters.  The ones we want to keep have a 'y' in
# the keep? column, and the ones that aren't actually whitespace (wtf,
# Python) are marked with an 'x'.
#
#  codepoint  category  keep?  name
#  000009     Cc        n      HT
#  00000A     Cc        n      LF
#  00000B     Cc        n      VT
#  00000C     Cc        n      FF
#  00000D     Cc        n      CR
#  00001C     Cc        x      FS
#  00001D     Cc        x      GS
#  00001E     Cc        x      RS
#  00001F     Cc        x      US
#  000020     Zs        n      SPACE
#  000085     Cc        n      NEL
#  0000A0     Zs        y      NO-BREAK SPACE
#  001680     Zs        y      OGHAM SPACE MARK
#  002000     Zs        y      EN QUAD
#  002001     Zs        y      EM QUAD
#  002002     Zs        y      EN SPACE
#  002003     Zs        y      EM SPACE
#  002004     Zs        y      THREE-PER-EM SPACE
#  002005     Zs        y      FOUR-PER-EM SPACE
#  002006     Zs        y      SIX-PER-EM SPACE
#  002007     Zs        y      FIGURE SPACE
#  002008     Zs        y      PUNCTUATION SPACE
#  002009     Zs        y      THIN SPACE
#  00200A     Zs        y      HAIR SPACE
#  002028     Zl        n      LINE SEPARATOR
#  002029     Zp        n      PARAGRAPH SEPARATOR
#  00202F     Zs        y      NARROW NO-BREAK SPACE
#  00205F     Zs        y      MEDIUM MATHEMATICAL SPACE
#  003000     Zs        n      IDEOGRAPHIC SPACE

WS_TO_FIRST_CHAR = re.compile(
    r"([\u00A0\u1680\u2000\u2001\u2002\u2003\u2004\u2005\u2006"
    r"\u2007\u2008\u2009\u202F\u205F])"
    r"[\u0009\u000A\u000B\u000C\u000D\u0020\u3000]+")

WS_TO_SPACE = re.compile(
    r"[\u0009\u000A\u000B\u000C\u000D\u0020\u0085\u2028\u2029\u3000]+")

# FIXME: Also zorch control characters.  The problem here is defining
# the set of control characters that should be zorched.

def canon_text_node(chunks, at_beg, at_end, in_pre):
    text = "".join(chunks)
    if not text:
        return ()

    if in_pre:
        # If we are at the end of the <pre>, we do not need to
        # preserve any trailing blank lines or any trailing whitespace
        # on the last nonblank line; if we are at the beginning of the
        # <pre>, we do not need to preserve any leading blank lines.
        # We never need to preserve trailing whitespace on lines 0
        # through N-1.  However, *leading* whitespace on nonblank
        # lines must always be preserved, as must interior blank
        # lines.  splitlines() considers \n as a line terminator, not
        # a separator, but if we are _not_ at the end of the <pre>, we
        # need to preserve the final \n and any subsequent horizontal
        # whitespace.
        lines = text.splitlines()
        # this is the set of characters on which splitlines() splits
        if text and text[-1] in "\n\r\v\f\x1c\x1d\x1e\x85\u2028\u2029":
            lines.append("")
        if lines:
           for i in range(len(lines)-1):
               lines[i] = lines[i].rstrip().expandtabs()
           lines[-1] = lines[-1].expandtabs()

        if at_beg:
            while lines and not lines[0]:
                lines.pop(0)
        if at_end:
            while lines and not lines[-1]:
                lines.pop()

        text = "\n".join(lines)
    else:
        # Replace collapsible whitespace following non-collapsible whitespace
        # with nothing.  Replace all surviving runs of collapsible whitespace
        # with a single space.
        text = WS_TO_FIRST_CHAR.sub(r"\1", text)
        text = WS_TO_SPACE.sub(" ", text)

        # If we are at the beginning of the paragraph, discard any
        # leading space; if we are at the end, discard any trailing
        # space.  Here, we want to discard both collapsible and non-
        # collapsible whitespace.
        if at_beg:
            text = text.lstrip()
        if at_end:
            text = text.rstrip()

    if text:
        return (text_node(text),)
    else:
        return ()


def clean_white_para(evlist):
    """Subroutine of clean_white which processes a single paragraph."""
    nev = len(evlist)
    assert nev >= 2
    assert evlist[0]["type"] == "StartTag"

    # Horizontal white space and the positions of newlines must be
    # preserved inside "pre" tags, but we still want to strip
    # trailing whitespace from each _line_, canonicalize line
    # breaks, eliminate hard tabs, and merge adjacent text nodes.
    # Also, little-known fact: it's perfectly valid to put HTML
    # phrasing-content tags inside a <pre>; it won't necessarily be
    # all one (run of) text nodes.
    in_pre = (evlist[0]["name"] == "pre")

    merged = []
    run = []
    first = None
    last = None
    for i, ev in enumerate(evlist):
        if ev["type"] == "Characters" or ev["type"] == "SpaceCharacters":
            if not run:
                first = i
            last = i
            run.append(ev["data"])
        else:
            # This run is at the beginning of the paragraph if its first
            # node was at position 1 in the evlist (not 0, because that
            # is the tag beginning the paragraph).  Similarly, it is at
            # the end of the paragraph if its last node was at position
            # n-2 in the evlist (not n-1, because that's the tag ending
            # the paragraph).  This doesn't handle things like
            # <pre><code> blah </code></pre> perfectly, but mandoc doesn't
            # appear ever to do that, so let's not worry about it.
            merged.extend(canon_text_node(run,
                                          first == 1,
                                          last  == nev - 2,
                                          in_pre))
            del run[:]
            first = None
            last = None
            merged.append(ev)
    assert not run

    # If no text survived this process, drop the entire paragraph.
    if len(merged) == 2:
        return []

    # Delete whitespace before <br>, and whitespace after <br> when
    # not in a <pre>.
    i = 0
    while i < len(merged):
        if merged[i]["type"] == "EmptyTag" and merged[i]["name"] == "br":
            # It's not possible for merged[0] to meet this condition,
            # because merged[0] is the tag beginning the paragraph,
            # which cannot be <br>.  Unlike above, in this context we
            # want to drop _all_ whitespace.
            if merged[i-1]["type"] == "Characters":
                merged[i-1]["data"] = merged[i-1]["data"].rstrip()
                if not merged[i-1]["data"]:
                    del merged[i-1]
                    i -= 1

            # Similarly, it's not possible for merged[-1] to meet this
            # condition, because that is the end tag.
            if (not in_pre and merged[i+1]["type"] == "Characters"):
                merged[i+1]["data"] = merged[i+1]["data"].lstrip()
                if not merged[i+1]["data"]:
                    del merged[i+1]

        i += 1

    return merged

def clean_white(events):
    """Strip whitespace that is totally insignificant, combine runs of
       adjacent text nodes into a single text node, and when textual
       formatting is insignificant, replace all runs of ASCII
       whitespace with a single space.
    """
    tag_stack = []
    run = []
    collecting = 0
    TO_COLLECT = frozenset((
        "p", "pre", "h1", "h2", "h3", "h4", "h5", "h6", "title", "td", "dt"))

    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            opening = ev["name"]
            tag_stack.append(opening)
            if opening in TO_COLLECT:
                collecting += 1
            if collecting:
                run.append(ev)
            else:
                yield ev

        elif ty == "EndTag":
            closing = tag_stack.pop()
            assert closing == ev["name"]

            if collecting:
                run.append(ev)
                if closing in TO_COLLECT:
                    collecting -= 1
                    if not collecting:
                        yield from clean_white_para(run)
                        del run[:]

            else:
                assert closing not in TO_COLLECT
                yield ev

        elif ty == "Characters":
            # Characters should only occur while collecting, because
            # every context where text can occur "loose" should have
            # been wrapped with <p> tags by form_paragraphs.
            assert collecting
            run.append(ev)

        elif ty == "SpaceCharacters":
            if collecting:
                run.append(ev)

        else:
            if collecting:
                run.append(ev)
            else:
                yield ev

    assert not tag_stack
    assert not collecting
    assert not run


def is_verbatim(ev):
    """True for start tags that introduce text styled as 'verbatim'
       (typewriter font, ASCII punctuation), False for start tags that
       do not do this, and None for anything other than a start tag."""
    ty = ev["type"]
    if ty != "StartTag":
        return None
    if ev["name"] in ("pre", "code"):
        return True
    if "Li" in ev["data"].get("class", "").split():
        return True
    return False


ADJUST_APOSTROPHE = re.compile(r"([a-z])'(?=[a-z]|\b)", re.IGNORECASE)
ADJUST_SUPERSCRIPT = re.compile(r"\*\*([+-−]?[0-9]+)")

def adjust_typography(events):
    """Make typographical improvements that are not practical either in
       the manpage source or in CSS.  Currently there are two of these:

       * Outside of <pre> and <code>, replace ' with ’ if it is either
         within a word, or at the end of a word and preceded by the
         letter S.  This could be done by writing \(aq instead of ' in
         the manpage source, but that makes the manpage source
         significantly harder to read (compare "Percival's" to
         "Percival\(aqs") and I expect people will forget to do it.
         When reading manpages in a terminal, straight quotes are
         acceptable.  Apostrophe at the beginning of a word is
         deliberately not changed, because 'x' (as in a C character
         literal) is much more likely to appear than ’Strewth!

       * Outside of <pre> and <code>, replace Fortran notation for
         exponents with superscripts, e.g. 2**56 becomes 2<sup>56</sup>.
         This could be done by writing .EQ 2 sup 56 .EN in the manpage
         source, but then we get literally "2 sup 56" in the terminal
         rendering, which is worse than "2**56".
    """

    tag_stack = []
    verbatim = 0

    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            nm = ev["name"]
            if is_verbatim(ev):
                verbatim += 1
                nm += "-v"
            tag_stack.append(nm)
            yield ev

        elif ty == "EndTag":
            nm = tag_stack.pop()
            if nm[-2:] == "-v":
                verbatim -= 1
                nm = nm[:-2]
            assert nm == ev["name"]
            yield ev

        elif ty == "Characters":
            if verbatim:
                yield ev
            else:
                text = ev["data"]
                text = ADJUST_APOSTROPHE.sub(r"\1’", text)

                runs = ADJUST_SUPERSCRIPT.split(text)
                while runs:
                    before = runs.pop(0)
                    if before: yield text_node(before)
                    if not runs: break
                    exponent = runs.pop(0)
                    if exponent[0] == '-': # a leading HYPHEN-MINUS becomes
                        exponent = '−' + exponent[1:] # a MINUS SIGN
                    yield start_tag("sup")
                    yield text_node(exponent)
                    yield end_tag("sup")
        else:
            yield ev

    assert not tag_stack
    assert not verbatim

def restructure_paragraph(evlist):
    """Make structural and/or typographical improvements that consider the
       contents of an entire paragraph as a whole.  Currently there is
       one of these:

       * If all of the text (not counting whitespace) in a paragraph
         is enclosed within <code>, <pre>, and/or <xx class="Li">
         elements, make the <p> be class="Li" also.  This works around
         a limitation in CSS, where you cannot style something based
         on whether or not its child elements have some property.
    """
    assert len(evlist) >= 3

    depth = 0
    for ev in evlist[1:-1]:
        ty = ev["type"]
        if ty == "StartTag":
            depth += 1
            if not is_verbatim(ev):
                break # at least one non-verbatim child element, don't change
        elif ty == "EndTag":
            depth -= 1
        elif ty == "Characters" and depth == 0:
            break # text outside of sub-elements, don't change
    else:
        # if we get here, we should make this change:
        p = evlist[0]
        assert p["type"] == "StartTag"
        assert p["name"] == "p"
        if "data" not in p:
            p["data"] = { "class": "Li" }
        else:
            attrs = p["data"]
            if "class" not in attrs:
                attrs["class"] = "Li"
            else:
                classes = set(attrs["class"].split())
                classes.add("Li")
                attrs["class"] = " ".join(sorted(classes))

    return evlist

def restructure_paragraphs(events):
    """Make structural and/or typographical improvements that consider the
       contents of entire paragraphs as a whole.
    """
    tag_stack = []
    pending = []
    p_depth = 0
    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            nm = ev["name"]
            tag_stack.append(nm)
            if nm == "p":
                p_depth += 1

        if p_depth:
            pending.append(ev)
        else:
            yield ev

        if ty == "EndTag":
            nm = tag_stack.pop()
            assert nm == ev["name"]
            if nm == "p":
                p_depth -= 1
                if not p_depth:
                    yield from restructure_paragraph(pending)
                    del pending[:]


def restructure_head_table(table):
    ltitle = []
    in_ltitle = False
    rtitle = []
    in_rtitle = False
    volume = []
    in_volume = False
    for ev in table:
        ty = ev["type"]
        if ty == "StartTag" and ev["name"] == "td":
            cls = ev["data"]["class"]
            if cls == "head-ltitle":
                in_ltitle = True
            elif cls == "head-rtitle":
                in_rtitle = True
            elif cls == "head-vol":
                in_volume = True
            else:
                raise RuntimeError("unexpected head-table class " + cls)
        elif ty == "EndTag" and ev["name"] == "td":
            in_ltitle = False
            in_rtitle = False
            in_volume = False
        else:
            if in_ltitle:
                ltitle.append(ev)
            elif in_rtitle:
                rtitle.append(ev)
            elif in_volume:
                volume.append(ev)

    if not ltitle:
        raise RuntimeError("title missing from head-table")
    if not volume:
        raise RuntimeError("volume missing from head-table")
    if ltitle != rtitle:
        raise RuntimeError("head-table: ltitle and rtitle don't match")

    yield start_tag("header")
    yield start_tag("h1")
    yield from ltitle
    yield end_tag("h1")
    yield start_tag("p", cls="man-volume")
    yield from volume
    yield end_tag("p")
    yield end_tag("header")

def restructure_foot_table(table):
    date = []
    in_date = False
    os = []
    in_os = False
    for ev in table:
        ty = ev["type"]
        if ty == "StartTag" and ev["name"] == "td":
            cls = ev["data"]["class"]
            if cls == "foot-date":
                in_date = True
            elif cls == "foot-os":
                in_os = True
            else:
                raise RuntimeError("unexpected foot-table class " + cls)
        elif ty == "EndTag" and ev["name"] == "td":
            in_date = False
            in_os = False
        else:
            if in_date:
                date.append(ev)
            elif in_os:
                os.append(ev)

    if not date:
        raise RuntimeError("date missing from foot-table")
    if not os:
        raise RuntimeError("os missing from foot-table")

    if len(date) == 1 and date[0]["type"] == "Characters":
        # Attempt to parse this as a date string in Month DD, YYYY
        # format; if successful, synthesize a <time> element.
        try:
            dt = datetime.datetime.strptime(date[0]["data"], "%B %d, %Y")
            date.insert(0, start_tag("time", datetime=dt.date().isoformat()))
            date.append(end_tag("time"))
        except ValueError:
            pass

    yield start_tag("footer")
    yield start_tag("p", cls="foot-date")
    yield from date
    yield end_tag("p")
    yield start_tag("p", cls="foot-os")
    yield from os
    yield end_tag("p")
    yield end_tag("footer")


def restructure_ATTRIBUTES_table(table):
    # mandoc doesn't fully implement tbl(1); in particular, it loses the
    # distinction between 'lb' and 'l' when emitting HTML, and it doesn't
    # implement macros within tables.  We can repair this for the ATTRIBUTES
    # tables because we know what they are supposed to look like: the first
    # row should be marked up with <th> instead of <td> and should be in
    # <thead> rather than <tbody>, and on the second and subsequent rows,
    # the first column should be a sequence of <code class="Nm"> identifiers
    # possibly separated with commas.
    thead = []
    tbody = []
    row = 0
    column = 0
    in_row = False
    in_cell = False
    for ev in table:
        ty = ev["type"]
        if ty == "StartTag" or ty == "EndTag":
            nm = ev["name"]
            if nm in ("table", "thead", "tbody"):
                assert not in_row
                assert not in_cell
                continue

            if nm == "tr":
                assert not in_cell
                if ty == "StartTag":
                    assert not in_row
                    in_row = True
                    row += 1
                    column = 0
                else:
                    assert in_row
                    in_row = False

            elif nm == "td":
                assert in_row
                if ty == "StartTag":
                    assert not in_cell
                    column += 1
                    in_cell = True
                    if row == 1:
                        ev = start_tag("th")
                else:
                    assert in_cell
                    in_cell = False
                    if row == 1:
                        ev = end_tag("th")

            else:
                assert in_row
                assert in_cell

            if row == 1:
                thead.append(ev)
            else:
                tbody.append(ev)

        elif ty == "Characters":
            assert in_row
            assert in_cell
            assert row > 0
            assert column > 0
            if row == 1:
                thead.append(ev)
            elif column > 1:
                tbody.append(ev)
            else:
                # row > 1, column == 1
                # this cell was written like so in the roff source:
                # T{
                # .Nm foo ,
                # .Nm bar
                # T}
                # but mandoc didn't honor the macros, so the cell contents
                # are something like "foo , bar" and we need to replace this
                # with the markup it would've generated if it did honor the
                # macros.
                for word in ev["data"].split():
                    if word == ",":
                        tbody.append(text_node(", "))
                    else:
                        tbody.append(start_tag("code", cls="Nm"))
                        tbody.append(text_node(word))
                        tbody.append(end_tag("code"))

        else:
            raise RuntimeError("unexpected event within ATTRIBUTES table: "
                               + repr(ev))

    yield start_tag("table", cls="tbl-attributes")
    yield start_tag("thead")
    yield from thead
    yield end_tag("thead")
    yield start_tag("tbody")
    yield from tbody
    yield end_tag("tbody")
    yield end_tag("table")

def restructure_table(table, in_ATTRIBUTES):
    cls = table[0]["data"]["class"]
    if cls == "head":
        return restructure_head_table(table)
    elif cls == "foot":
        return restructure_foot_table(table)
    elif cls == "tbl" and in_ATTRIBUTES:
        return restructure_ATTRIBUTES_table(table)
    else:
        return table

def restructure_tables(events):
    """Replace mandoc's "head" and "foot" tables with proper
       <header> and <footer> elements.  In the ATTRIBUTES section,
       correct the markup on a "tbl" table to what it would have been if
       mandoc supported macros inside tbl notation."""
    tag_stack = []
    table = []
    in_table = 0
    in_ATTRIBUTES = 0

    for ev in events:
        ty = ev["type"]

        if ty == "StartTag":
            tag_stack.append(ev["name"])
            if ev["name"] == "table":
                in_table += 1
            elif ev["name"] == "h1": # XXX h2 after we fix the sectioning
                in_ATTRIBUTES = ev["data"].get("id") == "ATTRIBUTES"

            if in_table:
                table.append(ev)
            else:
                yield ev

        elif ty == "EndTag":
            if in_table:
                table.append(ev)
            else:
                yield ev

            closing = tag_stack.pop()
            assert closing == ev["name"]
            if closing == "table":
                in_table -= 1
                if not in_table:
                    yield from restructure_table(table, in_ATTRIBUTES)
                    del table[:]

            elif closing == "section" or closing == "main":
                in_ATTRIBUTES = 0

        else:
            if in_table:
                table.append(ev)
            else:
                yield ev

def restore_namespaces(events):
    """Put back the namespace annotations we stripped at the beginning,
       so as not to confuse html5lib's serializer."""
    for ev in events:
        if isinstance(ev.get("data", None), dict):
            data = {}
            for key, val in ev["data"].items():
                if isinstance(key, str):
                    key = (None, key)
                data[key] = val
            ev["data"] = data
        yield ev

def fix_copyright_comment(comment, title):
    """Clean up the first comment in the file, which is typically
       copyright boilerplate."""
    # This regex is only run once so there's no point giving it a name.
    title = re.sub(r"^([A-Za-z0-9_]+)\(([0-9][a-z0-9_]*)\).*$", r"\1.\2",
                   title).lower()

    ctext = comment["data"].replace(
        " This is an automatically generated file.  Do not edit.\n",
        "\n   Generated from {} by mandoc(1) and postprocess-mandoc.\n\n"
        .format(title))
    ctext = re.sub("(?m)[ \t]+$", "", ctext)
    ctext = ctext.rstrip() + "\n"
    comment["data"] = ctext

def augment_head(events, *, style_url, language, input_file):
    """Add a <meta charset> and a stylesheet link to the <head>, and move
       the copyright-boilerplate comment inside the <head> so that it comes
       after the <meta charset> (which needs to be as close to the beginning
       of the file as possible).
    """
    copy = None
    title = ""
    head = []
    in_head = True
    in_title = True
    for ev in events:
        if not in_head:
            yield ev
            continue

        ty = ev["type"]
        if ty == "Doctype":
            yield ev

        elif ty == "StartTag":
            nm = ev["name"]
            if nm == "html":
                ev["data"]["lang"] = language
                yield ev
            elif nm == "head":
                yield ev
            elif nm == "title":
                in_title = True
            else:
                head.append(ev)

        elif ty == "EndTag":
            nm = ev["name"]
            if nm == "title":
                in_title = False
            elif nm == "head":
                fix_copyright_comment(copy, input_file)

                yield empty_tag("meta", charset="utf-8")
                yield copy
                yield start_tag("title")
                yield text_node(title)
                yield end_tag("title")
                yield empty_tag("link", rel="stylesheet", href=style_url)
                yield from head
                yield end_tag("head")

                in_head = False

        elif ty == "EmptyTag":
            head.append(ev)

        elif ty == "Comment":
            # Earlier transforms ensured that there is only one comment.
            copy = ev

        elif ty == "Characters":
            if not in_title:
                assert ev["data"].isspace()
                continue
            else:
                title += ev["data"]

        else:
            raise RuntimeError("Inappropriate event before <body>: " +
                               repr(ev))

def add_external_links(events, *, other_manpages_base, local_manpages):
    """Add links to external documents:

       * Rewrite cross-references to manpages not included in this set
         to point at an external repository containing all the common
         Unix manpages.
    """
    local_manpage_html = set(m + ".html" for m in local_manpages)
    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            if ev["name"] == "a":
                attrs = ev.get("data", {})
                if "href" in attrs:
                    target = attrs["href"]
                    if (target and target[0] != "#"
                        and "/" not in target
                        and target not in local_manpage_html):
                        attrs["href"] = urljoin(other_manpages_base, target)
        elif ty == "Characters":
            # future: create other links as directed by a config file or
            # something (we don't want to use .Lk because it mangles the
            # terminal-formatted manpage, but there are quite a few terms
            # that could use external references)
            pass

        yield ev

def form_sections_and_add_nav(events):
    """Demote all of mandoc's <h> tags a level (it uses H1 for sections,
       which is incorrect; H1 is reserved for the page title).  Generate
       explicit <section> tags, and move the section IDs from each <h> to its
       <section>.  Generate a <nav> list just below the <header> which
       links to each section (not subsection).  Rename the "permalink" class
       to the more appropriate "sect-link".
    """
    tag_stack = []
    in_main = False
    section_fragments = []
    section_stack = []
    current_sect  = None

    for ev in events:
        ty = ev["type"]
        if ty == "StartTag":
            nm = ev["name"]
            if nm == "main":
                assert not in_main
                in_main = True
                tag_stack.append(nm)
                section_stack.append([])
                current_sect  = section_stack[-1]
                continue

            # Pass through everything outside the 'main' element.
            if not in_main:
                tag_stack.append(nm)
                yield ev
                continue

            # H tags start (sub)sections and close any previous one.
            if len(nm) == 2 and nm[0] == "h":
                level = int(nm[1]) + 1
                frag_id = ev["data"]["id"]
                if level == 2:
                    section_fragments.append(frag_id)

                while len(section_stack) >= level:
                    # This conditional is only necessary to take care of the
                    # first <h> within <main>.
                    if current_sect:
                        current_sect.append(end_tag("section"))
                    section_stack.pop()
                    section_stack[-1].extend(current_sect)
                    current_sect = section_stack[-1]

                assert len(section_stack) == level - 1
                section_stack.append([])
                current_sect = section_stack[-1]

                current_sect.append(start_tag("section", id=frag_id))
                correct_tag = "h"+str(level)
                tag_stack.append(correct_tag)
                current_sect.append(start_tag(correct_tag))

            else:
                # Rewrite <a class="permalink">
                if nm == "a" and ev["data"].get("class") == "permalink":
                    ev["data"]["class"] = "sect-link"
                tag_stack.append(nm)
                current_sect.append(ev)

            continue

        if ty == "EndTag":
            nm = ev["name"]
            closed = tag_stack.pop()
            if not in_main:
                assert nm == closed
                yield ev
                continue

            if len(nm) == 2 and nm[0] == "h":
                if not (len(closed) == 2 and closed[0] == "h"):
                    sys.stderr.write("! {} {}\n".format(nm, closed))
                    assert False
                nlevel = int(nm[1])
                clevel = int(closed[1])
                assert clevel == nlevel + 1
                current_sect.append(end_tag(closed))
                continue

            elif nm != "main":
                if nm != closed:
                    sys.stderr.write("! {} {}\n".format(nm, closed))
                    assert False
                current_sect.append(ev)
                continue

            else:
                if nm != closed:
                    sys.stderr.write("! {} {}\n".format(nm, closed))
                    assert False
                assert in_main
                in_main = False
                assert section_stack
                while True:
                    current_sect.append(end_tag("section"))
                    section_stack.pop()
                    if not section_stack:
                        break
                    section_stack[-1].extend(current_sect)
                    current_sect = section_stack[-1]

                # ... emit the <nav> ...
                yield start_tag("nav", id="tn")
                yield start_tag("ul", id="tnU")
                for frag in section_fragments:
                    yield start_tag("li", cls="tnL")
                    yield start_tag("a", cls="tnA", href="#"+frag)
                    yield text_node(frag.replace("_", " "))
                    yield end_tag("a")
                    yield end_tag("li")
                yield end_tag("ul")
                yield end_tag("nav")

                # ... and then the <main> ...
                yield start_tag("main")
                yield from current_sect
                yield end_tag("main")
                current_sect = None

        if not in_main:
            yield ev
            continue

        current_sect.append(ev)


#
# Utility routines for I/O
#

def RandomNameSequence():
    characters = "abcdefghijklmnopqrstuvwxyz0123456789_"
    choose  = Random().choice
    range_  = range
    paste   = ''.join
    scratch = [None]*8
    while True:
        for i in range(8):
            scratch[i] = choose(characters)
        yield paste(scratch)

SUFFIXES = RandomNameSequence()

def atomic_replace_with_symlink(src, dst):
    """Like os.symlink, but atomically replaces any existing 'dst'
       (whether or not that was a symlink)."""
    for suffix in SUFFIXES:
        tdst = dst + suffix
        try:
            os.symlink(src, tdst)
            break
        except FileExistsError:
            continue
    os.rename(tdst, dst)

@contextmanager
def atomic_rewrite(dst, *args, **kwargs):
    """Atomically replace 'dst' with a new regular file.

       This function is a context manager; entering the context makes
       a file object available.  Whatever is written to that object
       will be the new contents of the file at 'dst'.  Upon
       successfully exiting the context, the file is flushed, closed,
       and only then atomically replaces the previous file at 'dst',
       if any.

       Arguments besides 'dst' will be passed on to open().  Note that
       the default 'mode' parameter for open() is 'rt', which doesn't
       make sense for this operation; callers should typically specify
       a mode of 'wt' or 'wb'.

    """
    tdst = None
    fp = None
    try:
        for suffix in SUFFIXES:
            try:
                tdst = dst + suffix
                fp = open(tdst, *args, **kwargs)
                break
            except FileExistsError:
                continue

        yield fp

    except:
        if fp is not None:
            fp.close()
        if tdst is not None:
            os.remove(tdst)
        raise

    else: # successful completion of the context
        fp.close()
        os.rename(tdst, dst)

#
# Master control
#

def page_is_alias(fname):

    """Detect manpages that are alternative names for other manpages.

    That is, if fname is either a symlink, or a regular file
    containing a single .so request, return the name of the
    target file, with any leading directories stripped.
    Otherwise return None.
    """
    if os.path.islink(fname):
        return os.path.basename(os.readlink(fname))

    with open(fname, "rt") as f:
         firstline = next(f, "")
         if not firstline.startswith(".so "):
             return None

         secondline = next(f, None)
         if secondline is not None:
             return None

         return os.path.basename(firstline[4:].strip())

def mdoc2html(fname, args):
    bname = os.path.basename(fname)
    oname = os.path.join(args.output_dir, bname + ".html")

    aname = page_is_alias(fname)
    if aname:
        atomic_replace_with_symlink(aname + ".html", oname)
        return

    with subprocess.Popen([
            "mandoc", "-T", "html", "-O", "man=%N.%S.html", fname
    ], stdout=subprocess.PIPE) as proc:
        idom = html5lib.parse(proc.stdout, treebuilder="dom")
        status = proc.wait()
        if status:
            raise subprocess.CalledProcessError(status, "mandoc")

    walker = html5lib.getTreeWalker("dom")
    serializer = html5lib.serializer.HTMLSerializer(
        quote_attr_values   = "always",
        strip_whitespace    = False,
        omit_optional_tags  = False,
        inject_meta_charset = False
    )
    passes = [
        walker,
        remove_unwanted,
        fixup_mandoc_pseudos,
        unlink_literals,
        form_paragraphs,
        clean_white,
        adjust_typography,
        restructure_paragraphs,
        restructure_tables,
        partial(augment_head,
                style_url=args.style_url,
                language=args.language,
                input_file=bname),
        partial(add_external_links,
                other_manpages_base=args.other_manpages_base,
                local_manpages=args.inputs),
        form_sections_and_add_nav,
        restore_namespaces,
        serializer.serialize
    ]
    with idom, \
         atomic_rewrite(oname, "wt", encoding="utf-8", newline="\n") as ofp:
        blob = idom
        for pass_ in passes:
            blob = pass_(blob)
        for item in blob:
            ofp.write(item)


def main():
    ap = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    ap.add_argument("--language", default="en",
                    help="Language of the documentation (BCP47 code)")
    ap.add_argument("--other-manpages-base", default="http://link.invalid/",
                    help="URL of a repository containing other manpages. "
                    "Cross-references to manpages not in the inputs list "
                    "will link to this repository.")
    ap.add_argument("--style-url", default="man.css",
                    help="URL of the CSS file to reference.")
    ap.add_argument("-o", "--output-dir", default=".",
                    help="Where to write the output HTML files.")
    ap.add_argument("--debug", action="store_true",
                    help="Print detailed exceptions for debugging.")
    ap.add_argument("inputs", nargs="+", metavar="input",
                    help="Input manpages.")
    args = ap.parse_args()

    status = 0
    for fname in args.inputs:
        try:
            mdoc2html(fname, args)
        except subprocess.CalledProcessError as exc:
            status = 1
            # If mandoc just exited unsuccessfully, we assume it
            # already printed an error message.  But if it caught a
            # fatal signal, report that.
            if exc.returncode < 0:
                sys.stderr.write("{}: {}\n".format(fname, exc))

        except Exception as exc:
            status = 1
            if args.debug:
                sys.stderr.write("*** {}:\n".format(fname))
                import traceback
                traceback.print_exc()

            else:
                sys.stderr.write("{}: {}: {}\n".format(
                    fname, type(exc).__name__, exc))

    return status

sys.exit(main())
